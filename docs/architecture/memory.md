# Память

Два типа памяти: кэширование токенов и история разговора.

## Token Caching

**Проблема:** Системные промпты отправляются с каждым запросом → платим за одно и то же.

**Решение:** Gemini позволяет кэшировать контент на их стороне.

```
Без кэша:                         С кэшем:
┌─────────────────────┐           ┌─────────────────────┐
│ System prompt (2K)  │ ←платим   │ cached_content: xxx │ ←90% скидка
│ User message (100)  │ ←платим   │ User message (100)  │ ←платим
└─────────────────────┘           └─────────────────────┘
```

**Экономия:** 73% на токенах.

Кэшируются:
- Parser system prompt
- Clarifier system prompt

Не кэшируются (слишком маленькие):
- Responder prompt

## Conversation Memory

**Проблема:** Нужно помнить что обсуждали раньше.

**Решение:** Трёхуровневая память.

```
┌─────────────────────────────────────┐
│           Recent (5-10 msgs)        │ ← полный текст
├─────────────────────────────────────┤
│         Summaries (старое)          │ ← сжатое
├─────────────────────────────────────┤
│         Key Facts (важное)          │ ← "user prefers RU"
└─────────────────────────────────────┘
```

- **Recent:** последние 5-10 сообщений, полный текст
- **Summaries:** старые сообщения сжимаем в summary
- **Key Facts:** важные факты о пользователе

## Memory Manager

Singleton — одна память на сессию:

```
Session 1: ConversationMemory
Session 2: ConversationMemory
Session 3: ConversationMemory
```

При старте графа — загружаем память.
При завершении — сохраняем ответ.

```
START → load_memory → ... → save_memory → END
```

## Будущее: Supabase

Сейчас память в RAM. Планируется:
- Персистенция в Supabase
- История между сессиями
- Аналитика разговоров
